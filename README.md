| Название проекта | Описание | Используемые библиотеки | 
| ---------------------- | ---------------------- | ---------------------- |
| [Машинное обучение для текстов](ML_for_texts) | Обучение модели классификации комментариев на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.Значением метрики качества F1 должно быть не меньше 0.75. Данные находятся в файле /datasets/toxic_comments.csv(источник Яндекс.Практикум). Столбец text в нём содержит текст комментария, а toxic — целевой признак с разметкой о токсичности| *Python, Pandas, BERT, nltk, tf-idf* |
| ---------------------- | ---------------------- | ---------------------- |
| [Определение выгодного тарифа для телеком-компании](the_best_telecom_tariff) | У сотовой компании два тарифных плана: «Смарт» и «Ультра». Необходимо понять, какой тариф приносит больший доход. На небольшой выборке клиентов необходимо провести анализ: кто они, откуда, каким тарифом пользуются, сколько звонков и сообщений каждый отправил за 2018 год. Нужно сделать вывод — какой тариф лучше.| *Python, Pandas, Matplotlib, NumPy, SciPy, проверка статистических гипотез* |
| ---------------------- | ---------------------- | ---------------------- |
| [Прогнозирование заказов такси](taxi_order_forecasting) | Необходимо спрогнозировать количество заказов такси на следующий час, опираясь на исторические данные о заказах такси в аэропортах. Значение метрики RMSE на тестовой выборке должно быть не больше 48, размер тестовой выборки - 10% от исходных данных. | *lightgbm, matplotlib.pyplot, nltk,, numpy, pandas, re, tensorflow_hub, time, torch, transformers, google.colab, itertools, RandomForestClassifier, TfidfVectorizer, LogisticRegression, f1_score, train_test_split, GridSearchCV, make_pipeline, DecisionTreeClassifier, class_weight, TextBlob, Word, notebook, BertTokenizer, TFBertModel* |
| ---------------------- | ---------------------- | ---------------------- |
